{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A. Web Scraping\n",
    "\n",
    "- October 24 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The roadmap\n",
    "\n",
    "Moving in to our \"getting data\" modules\n",
    "\n",
    "- Today: web scraping, APIs, Census data, (natural language processing - some basics)\n",
    "- Then: big data, geo data science in the wild, dashboarding & web servers, machine learning\n",
    "\n",
    "*The final project will ask you to combine several of these topics/techniques to analyze a data sets and produce a web-based data visualization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today: web scraping & API\n",
    "\n",
    "- Why web scraping? \n",
    "- Getting familiar with the Web\n",
    "- Web scraping: extracting data from static sites\n",
    "- API (weather, google, etc...)\n",
    "- (we won't cover dynamic contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is web scraping? \n",
    "\n",
    "Using software to gather and extract data/content from websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is web scraping useful? \n",
    "\n",
    "- Not every data source provides an API\n",
    "- The Web contains **a lot** of information\n",
    "- Unique data sources that may not be available elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is possible: 11 million rental listings from Craigslist\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/scraping-craigslist.jpeg\" width=500></img>\n",
    "</center>\n",
    "\n",
    "[Source: Geoff Boeing](https://geoffboeing.com/2016/08/craigslist-rental-housing-insights/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why isn't web scraping incredibly popular?\n",
    "\n",
    "- It can be time consuming and difficult to extract large volumes \n",
    "- You are at the mercy of website maintainers — if the website structure changes, your code breaks\n",
    "- Most importantly, there are ethical and legal concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"imgs/google-search.png\" width=700></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Legal concerns\n",
    "\n",
    "RadPad scraped the entirety of Craiglist, Craigslist sued RadPad, and they were [awarded $60 million](http://labusinessjournal.com/news/2017/apr/14/radpad-ordered-pay-605-million-judgment-craigslist/)\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/radpad.png\" width=400></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two types of legal issues\n",
    "\n",
    "1. Copyright infringement\n",
    "    - For example: pictures, rental listing text\n",
    "2. Terms of Use violations\n",
    "    - **Unauthorized**: Is scraping prohibited in the website’s terms of use?\n",
    "    - **Intentional**: Was the person aware of the terms? Did they check an “I agree to these terms” box?\n",
    "    - **Causes damage**: Did the scraping overload the website, blocking user access?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping public sites is legal\n",
    "\n",
    "- Ruling from 2022 said that scraping data that is publicly accessible on the internet is not a violation of the Computer Fraud and Abuse Act\n",
    "- Linkedin had sued a competitor for scraping publicly available information from user profiles\n",
    "\n",
    "\n",
    "[More info on the case](https://techcrunch.com/2022/04/18/web-scraping-legal-court/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more problematic use cases\n",
    "\n",
    "- The facial recognition startup Clearview AI scraped billions of photos from social media websites. They [recently settled](https://www.mediapost.com/publications/article/389525/facial-recognition-company-clearview-settles-priva.html) a class action lawsuit that alleged they violated privacy laws\n",
    "- Web scraping at a massive scale has been a key ingredient in generating the training datasets for generative AI models like ChatGPT. Companies like OpenAI and Meta [have been sued](https://apnews.com/article/openai-lawsuit-authors-grisham-george-rr-martin-37f9073ab67ab25b7e6b2975b2a63bfe) by authors and other content creators for violating copyright laws.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When is web scraping probably okay?\n",
    "\n",
    "- .gov sites and, to a lesser degree, .edu sites\n",
    "- Website owner has no business reason to protect the information\n",
    "- Not prohibited in terms of use\n",
    "- Limited number of requests\n",
    "- Not too many requests all at once\n",
    "- Done at night, when web traffic is low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When is it less likely to be okay?\n",
    "\n",
    "- search engines\n",
    "- E-commerce sites (e.g. Zillow, Expedia, Amazon)\n",
    "- Social media\n",
    "- Prohibited in terms of use\n",
    "- Large number of requests\n",
    "- High frequency of requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**With that being said, let's do some web scraping...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A primer on Web definitions\n",
    "\n",
    "So many acronyms:\n",
    "\n",
    "- HTML\n",
    "- CSS\n",
    "- The DOM (for dynamic contents - not covered this year)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. HTML: HyperText Markup Language\n",
    "\n",
    "- The language most websites are written in\n",
    "- The browser knows how to read this language and renders the output for you\n",
    "- HTML is what a web crawler will see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### HTML tags\n",
    "\n",
    "- There are a standard set of tags to define the different structural components of a webpage\n",
    "- For example: \n",
    "    - `<h1>`, `<h2>` tags define headers\n",
    "    - `<p>` tags define paragraphs\n",
    "    - `<ol>` and `<ul>` are ordered and unordered lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Jupyter notebooks can render HTML\n",
    "\n",
    "Use the `%%html` magic cell command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<html>\n",
       "  <head>\n",
       "    <title>TITLE GOES HERE</title>\n",
       "  </head>\n",
       "  <body>\n",
       "    <h3>MAIN CONTENT GOES IN THE BODY TAG</h3>\n",
       "    <p>This is a paragraph tag</p>\n",
       "    <p>This is a second paragraph tag</p>\n",
       "  </body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<html>\n",
    "  <head>\n",
    "    <title>TITLE GOES HERE</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h3>MAIN CONTENT GOES IN THE BODY TAG</h3>\n",
    "    <p>This is a paragraph tag</p>\n",
    "    <p>This is a second paragraph tag</p>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Elements, tags, and attributes\n",
    "\n",
    "Learning the notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<a id=\"my-link\" style=\"color: orange;\" href=\"https://www.design.upenn.edu\" target=\"blank_\">This is my link</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<a id=\"my-link\" style=\"color: orange;\" href=\"https://www.design.upenn.edu\" target=\"blank_\">This is my link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The element:** ![](imgs/atag-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The tag:**\n",
    "![](imgs/atag-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The attributes:**\n",
    "\n",
    "![](imgs/atag-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some attributes have special meaning\n",
    "\n",
    "- In particular: `id` and `class`\n",
    "- Allows you to: \n",
    "    - select and manipulate specific elements\n",
    "    - apply styling to specific types of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. CSS: Cascading Stylesheets\n",
    "\n",
    "- A language for styling HTML pages\n",
    "- CSS styles (also known as selectors) are applied to HTML tags based on their name, class, or ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"imgs/css.png\" width=\"1200\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Web selectors\n",
    "\n",
    "- Class\n",
    "    - e.g., `.red`\n",
    "- ID\n",
    "    - e.g., `#some-id`\n",
    "- Tag\n",
    "    - e.g., `p`, `li`, `div`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- **IDs:** unique identifiers\n",
    "    - no two elements on a page will have the same ID.\n",
    "- **Classes:** not unique\n",
    "    - many elements will have the same class\n",
    "    - a single element can have multiple classes\n",
    "    \n",
    "And many more: look up the syntax when you need it\n",
    "\n",
    "[https://www.w3schools.com/cssref/css_selectors.asp](https://www.w3schools.com/cssref/css_selectors.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inspecting a webpage\n",
    "\n",
    "- Modern web browsers provide tools for inspecting the source HTML and DOM of websites\n",
    "- Also tells you data sources that have been loaded by the page\n",
    "- This should also be your first step when starting to scrape a page\n",
    "\n",
    "::: {.callout-tip}\n",
    "To load the Web Inspector in most modern browsers, you can simply hit the F12 button\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/web-inspector-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Elements tab\n",
    "\n",
    "- Allows you to inspect the DOM directly\n",
    "- The tool that will allow you to identify what data you want to scrape from a website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/web-inspector-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Web scraping demo: Philadelphia Health Inspections\n",
    "\n",
    "Let's scrape data for restaurant inspections using the searchable database maintained by the Philadelphia Inquirer, available at: [https://data.inquirer.com/inspections/](https://data.inquirer.com/inspections/)\n",
    "\n",
    "![](imgs/clean-plates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Getting the HTML content\n",
    "\n",
    "We'll use the built-in \"requests\" module to request the content of the website and load it into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a \"get\" request to get the content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://data.inquirer.com/inspections/\"\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### BeautifulSoup makes this much more manageable\n",
    "\n",
    "[BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) makes it much easier to extract out different parts of a website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the \"soup\" object, using the content of our get request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making the HTML \"pretty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is what you'll see if you use the Web Inspector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to extract the content we want?\n",
    "\n",
    "**Two important functions**\n",
    "\n",
    "1. `soup.select_one(selector)`: finds the first element matching the selector query and returns **one** element\n",
    "1. `soup.select(selector)`: finds **all** elements matching the selector \n",
    "\n",
    "**Recommended reading:** Note on beautiful soup and css selectors in [this week's repository](https://github.com/MUSA-550-Fall-2023/week-6/blob/master/css-selectors.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### To the Web Inspector!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use the web inspector to understand the structure of the website and identify the HTML tags that we want to extract content from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's select the first row\n",
    "\n",
    "Web browsers will let us copy the CSS selector for individual elements.\n",
    "\n",
    "Use: **Right Click > Copy > Copy Selector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = \"#inspection_unit_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Select the first row\n",
    "# NOTE: we are using \"select_one()\" to select only one matching element\n",
    "first_row = soup.select_one(selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"inspectionUnit inspectionUnitEven transitionBackground\" id=\"inspection_unit_0\"><a href=\"https://data.inquirer.com/inspections/philly/?detail=Bamba%20and%20Saduty%20Produce%20Market|4603%20FRANKFORD%20AVE%2019124\"><div class=\"inspectionUnitInner\"><div class=\"inspectionNameWrapper\"><div class=\"inspectionUnitName transitionAll\">Bamba and Saduty Produce Market</div><div class=\"inspectionUnitDate\"><span class=\"inspectionUnitDateTitle\">Inspection date:</span> Apr 18, 2024</div><div class=\"clearAll\"></div></div><div class=\"inspectionUnitInfoWrapper\"><div class=\"inspectionUnitAddress\">4603 FRANKFORD AVE 19124</div><div class=\"inspectionUnitNeigborhood\"></div><div class=\"clearAll\"></div></div><div class=\"inspectionUnitCountWrapper\"><span class=\"inspectionCountLabel\">Violations</span><li class=\"inspectionUnitCount inspectionUnitCountFoodborne inspectionUnitCountFirst\"><span class=\"inspectionCountNumber\">5</span><span class=\"inspectionUnitInfoItemTitle\"><span class=\"inspectionUnitInfoItemTitleLabel\">Foodborne Illness Risk Factors</span></span></li><li class=\"inspectionUnitCount inspectionUnitCountRetail\"><span class=\"inspectionCountNumber\">10</span><span class=\"inspectionUnitInfoItemTitle\"><span class=\"inspectionUnitInfoItemTitleLabel\">Lack of Good Retail Practices</span></span></li><div class=\"clearAll\"></div></div><div class=\"clearAll\"></div></div></a></div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But we need all of the rows!\n",
    "\n",
    "When you use Copy -> Copy Selector, the copied css selector will only match the specific element you've highlighted, no others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalizing your selectors\n",
    "\n",
    "We need to **generalize the selector** to just select all rows from the table, not just the first one. To do this, we'll need to go back to the web inspector and understand the structure of the website. \n",
    "\n",
    "\n",
    "When trying to identify a general selector, try to look for common patterns, like shared class names or id strings, across the tags you want to extract.\n",
    "\n",
    "\n",
    "In our case, it looks like the \"inspectionUnit\" class is shared across all of the row div elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/clean-plates-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get all tags with the inspectionUnit class name\n",
    "# Note we are using select() to select ALL elements\n",
    "rows = soup.select('.inspectionUnit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# get the first row\n",
    "row = rows[0]\n",
    "\n",
    "#print(row.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, let's extract out the content from each row\n",
    "\n",
    "We'll look for the following items:\n",
    "\n",
    "1. The link to the full inspection report\n",
    "1. The name of the restaurant\n",
    "1. The restaurant address\n",
    "1. The number of *food-borne violations*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The report link\n",
    "\n",
    "The link is stored as the \"href\" attribute of the first \"a\" element:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://data.inquirer.com/inspections/philly/?detail=Bamba%20and%20Saduty%20Produce%20Market|4603%20FRANKFORD%20AVE%2019124\"><div class=\"inspectionUnitInner\"><div class=\"inspectionNameWrapper\"><div class=\"inspectionUnitName transitionAll\">Bamba and Saduty Produce Market</div><div class=\"inspectionUnitDate\"><span class=\"inspectionUnitDateTitle\">Inspection date:</span> Apr 18, 2024</div><div class=\"clearAll\"></div></div><div class=\"inspectionUnitInfoWrapper\"><div class=\"inspectionUnitAddress\">4603 FRANKFORD AVE 19124</div><div class=\"inspectionUnitNeigborhood\"></div><div class=\"clearAll\"></div></div><div class=\"inspectionUnitCountWrapper\"><span class=\"inspectionCountLabel\">Violations</span><li class=\"inspectionUnitCount inspectionUnitCountFoodborne inspectionUnitCountFirst\"><span class=\"inspectionCountNumber\">5</span><span class=\"inspectionUnitInfoItemTitle\"><span class=\"inspectionUnitInfoItemTitleLabel\">Foodborne Illness Risk Factors</span></span></li><li class=\"inspectionUnitCount inspectionUnitCountRetail\"><span class=\"inspectionCountNumber\">10</span><span class=\"inspectionUnitInfoItemTitle\"><span class=\"inspectionUnitInfoItemTitleLabel\">Lack of Good Retail Practices</span></span></li><div class=\"clearAll\"></div></div><div class=\"clearAll\"></div></div></a>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = row.select_one(\"a\")\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes can be extracted from the \"attrs\" attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'href': 'https://data.inquirer.com/inspections/philly/?detail=Bamba%20and%20Saduty%20Produce%20Market|4603%20FRANKFORD%20AVE%2019124'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://data.inquirer.com/inspections/philly/?detail=Bamba%20and%20Saduty%20Produce%20Market|4603%20FRANKFORD%20AVE%2019124'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = a.attrs['href']\n",
    "\n",
    "link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. The restaurant name\n",
    "\n",
    "Use the \"inspectionUnitName\" class name to identify the right element.\n",
    "\n",
    "![](imgs/clean-plates-name.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"inspectionUnitName transitionAll\">Bamba and Saduty Produce Market</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the . to specify class name\n",
    "name_tag = row.select_one(\".inspectionUnitName\")\n",
    "\n",
    "name_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bamba and Saduty Produce Market'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = name_tag.text\n",
    "\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. The restaurant address\n",
    "\n",
    "Use the \"inspectionUnitAddress\" class name to identify the right element.\n",
    "\n",
    "![](imgs/clean-plates-address.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"inspectionUnitAddress\">4603 FRANKFORD AVE 19124</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the . to specify class name\n",
    "addr_tag = row.select_one(\".inspectionUnitAddress\")\n",
    "\n",
    "addr_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4603 FRANKFORD AVE 19124'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = addr_tag.text\n",
    "\n",
    "address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. The number of food-borne violations\n",
    "\n",
    "It looks like the count number is within an element with class \"inspectionCountNumber\". BUT: this class is repeated on the retail violations element as well as the food-borne violations element. So, we'll need to use *nested* selectors\n",
    "\n",
    "First, select elements with the \"inspectionUnitCountFoodborne\" class name and then the \"inspectionCountNumber\" class name.\n",
    "\n",
    "![](imgs/clean-plates-violations.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of foodborne violations\n",
    "count = row.select_one(\".inspectionUnitCountFoodborne .inspectionCountNumber\")\n",
    "\n",
    "int(count.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the violations count is zero, there won't be any element that matches the above selector (the website instead uses a \"inspectionUnitCountZero\" class. \n",
    "\n",
    "If the element doesn't exist, the `select_one()` function will return \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Putting it all together\n",
    "\n",
    "Now, we can put this code into a for loop and extract out the content from every row on the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Store the data from each row\n",
    "data = []\n",
    "\n",
    "# Step 1: Get all rows\n",
    "rows = soup.select(\".inspectionUnit\")\n",
    "\n",
    "# Loop over all rows\n",
    "for this_row in rows:\n",
    "    \n",
    "    # Step 2: Get the report link\n",
    "    # Note: we are using the \"this_row\" variable from the for loop\n",
    "    a = this_row.select_one(\"a\")\n",
    "    url = a.attrs[\"href\"]\n",
    "\n",
    "    # Step 3: Get the name\n",
    "    name_tag = this_row.select_one(\".inspectionUnitName\")\n",
    "    name = name_tag.text\n",
    "\n",
    "    # Step 4: Get the name\n",
    "    addr_tag = this_row.select_one(\".inspectionUnitAddress\")\n",
    "    address = addr_tag.text\n",
    "\n",
    "    # Step 5: Get the violation count\n",
    "    count_tag = this_row.select_one(\".inspectionUnitCountFoodborne .inspectionCountNumber\")\n",
    "\n",
    "    # If there were no matches (None was returned), it means the count was zero\n",
    "    if count_tag is None:\n",
    "        count = 0\n",
    "    else:\n",
    "        count = int(count_tag.text)\n",
    "\n",
    "    # Step 6: Save it\n",
    "    data.append(\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"address\": address,\n",
    "            \"foodborne_count\": count,\n",
    "            \"url\": url,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a dataframe\n",
    "scraped_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by violation count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>foodborne_count</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bamba and Saduty Produce Market</td>\n",
       "      <td>4603 FRANKFORD AVE 19124</td>\n",
       "      <td>5</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fado Pub</td>\n",
       "      <td>1500 LOCUST ST 19102</td>\n",
       "      <td>5</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Gvinianidze Arts and Music Center</td>\n",
       "      <td>716 RED LION RD 19115</td>\n",
       "      <td>5</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DiBruno Brothers</td>\n",
       "      <td>1730 CHESTNUT ST 19103</td>\n",
       "      <td>5</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hayashi Sushi &amp; Poke</td>\n",
       "      <td>814 S 47TH ST 19143</td>\n",
       "      <td>4</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Asaad Halal Gyro/MC Crepes/V03396</td>\n",
       "      <td>7300 E ROOSEVELT BLVD 19149</td>\n",
       "      <td>4</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A &amp; S Deli</td>\n",
       "      <td>2848 S 17TH ST 19145</td>\n",
       "      <td>4</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Carangi Baking Company</td>\n",
       "      <td>2655 S ISEMINGER ST 19148</td>\n",
       "      <td>3</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Espinal and Ramos Grocery</td>\n",
       "      <td>2000 MEDARY AVE 19138</td>\n",
       "      <td>2</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DiBruno Brothers Events &amp; Catering</td>\n",
       "      <td>435 FAIRMOUNT AVE 19123</td>\n",
       "      <td>2</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dunkin Donuts</td>\n",
       "      <td>5801 OXFORD AVE 19149</td>\n",
       "      <td>2</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bright Horizons at Philadelphia Cathedral Lear...</td>\n",
       "      <td>23 S 38TH ST 19104</td>\n",
       "      <td>2</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Buddy Buddy Beer</td>\n",
       "      <td>9037 ASHTON RD 19136</td>\n",
       "      <td>2</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dennis Harding/ Curbside Creamery/ V08867</td>\n",
       "      <td>NON PERMANENT LOCATION 19107</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Domino's Pizza</td>\n",
       "      <td>6001 LANCASTER AVE 19151</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Aramingo Sunoco</td>\n",
       "      <td>2750 ARAMINGO AVE 19134</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bayard Taylor School Annex</td>\n",
       "      <td>602 W ERIE AVE 19140</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Camuy's Bar</td>\n",
       "      <td>2965 N 3RD ST 19133</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>China Wok Restaurant</td>\n",
       "      <td>4613 FRANKFORD AVE 19124</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ahmed, Sherif/ Tony Express/ V08085</td>\n",
       "      <td>3343 N BROAD ST 19140</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B2</td>\n",
       "      <td>1500 E PASSYUNK AVE 19147</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Crown Fried Chicken</td>\n",
       "      <td>5824 RISING SUN AVE 19120</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>El Pastorcito Tacos</td>\n",
       "      <td>1532 E WADSWORTH AVE 19150</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chucks Helados Water Ice Inc</td>\n",
       "      <td>1835 SNYDER AVE 19145</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Engimono Sushi</td>\n",
       "      <td>1811 FAIRMOUNT AVE 19130</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Future Academy Child Care &amp; Learning Center</td>\n",
       "      <td>3323 TUDOR ST 19136</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HP 9 Convenience Store</td>\n",
       "      <td>4163 N 9TH ST 19140</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Kotridis, Antigoni/Lunch Cart/V#00848</td>\n",
       "      <td>6 S 13TH ST 19107</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Metropolitan Bakery</td>\n",
       "      <td>262 S 19TH ST 19103</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CVS/Pharmacy #11170</td>\n",
       "      <td>1201 WALNUT ST 19107</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hope Partnership for Education</td>\n",
       "      <td>2601 N 11TH ST 19133</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gong Cha</td>\n",
       "      <td>1122 WASHINGTON AVE UNIT J 19147</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Girard BP</td>\n",
       "      <td>4708 W GIRARD AVE 19131</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Girard Annex GAMP</td>\n",
       "      <td>2198 RITNER ST 19145</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Famous Gourmet Deli and Restaurant</td>\n",
       "      <td>1619 GRANT AVE 19115</td>\n",
       "      <td>1</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Advance Auto Parts #8775</td>\n",
       "      <td>8423 FRANKFORD AVE STE A 19136</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Asad's Hot Chicken</td>\n",
       "      <td>1247 S 47TH ST 19143</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Eliza Kirkbride School</td>\n",
       "      <td>1501 S 07TH ST 19147</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>High Time Convenience Store</td>\n",
       "      <td>1702 CECIL B. MOORE AVE 19121</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hare Krishna Temple</td>\n",
       "      <td>41 W ALLENS LN 19119</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Haegele's Bakery</td>\n",
       "      <td>4164 BARNETT ST 19135</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>FedEx</td>\n",
       "      <td>216 S 16TH ST 19102</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CVS - #2986</td>\n",
       "      <td>7065 LINCOLN DR 19119</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Cuddle 'n' Care</td>\n",
       "      <td>7707 GERMANTOWN AVE 19118</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>China House</td>\n",
       "      <td>331 SPRING GARDEN ST 19123</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Chill on the Hill</td>\n",
       "      <td>5 E HIGHLAND AVE SPC 1 19118</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Cathedral Village</td>\n",
       "      <td>600 E CATHEDRAL RD 19128</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Bayard Taylor School</td>\n",
       "      <td>528 W ERIE AVE 19140</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Ali, Mansoor /Bilal Gyro/ V07637</td>\n",
       "      <td>2420 COTTMAN AVE 19149</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Benny Peretti's</td>\n",
       "      <td>4320 MAIN ST 19127</td>\n",
       "      <td>0</td>\n",
       "      <td>https://data.inquirer.com/inspections/philly/?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "0                     Bamba and Saduty Produce Market   \n",
       "1                                            Fado Pub   \n",
       "2             David Gvinianidze Arts and Music Center   \n",
       "3                                    DiBruno Brothers   \n",
       "4                                Hayashi Sushi & Poke   \n",
       "5                   Asaad Halal Gyro/MC Crepes/V03396   \n",
       "6                                          A & S Deli   \n",
       "7                              Carangi Baking Company   \n",
       "8                           Espinal and Ramos Grocery   \n",
       "9                  DiBruno Brothers Events & Catering   \n",
       "10                                      Dunkin Donuts   \n",
       "11  Bright Horizons at Philadelphia Cathedral Lear...   \n",
       "12                                   Buddy Buddy Beer   \n",
       "13          Dennis Harding/ Curbside Creamery/ V08867   \n",
       "14                                     Domino's Pizza   \n",
       "15                                    Aramingo Sunoco   \n",
       "16                         Bayard Taylor School Annex   \n",
       "17                                        Camuy's Bar   \n",
       "18                               China Wok Restaurant   \n",
       "19                Ahmed, Sherif/ Tony Express/ V08085   \n",
       "20                                                 B2   \n",
       "21                                Crown Fried Chicken   \n",
       "22                                El Pastorcito Tacos   \n",
       "23                       Chucks Helados Water Ice Inc   \n",
       "24                                     Engimono Sushi   \n",
       "25        Future Academy Child Care & Learning Center   \n",
       "26                             HP 9 Convenience Store   \n",
       "27              Kotridis, Antigoni/Lunch Cart/V#00848   \n",
       "28                                Metropolitan Bakery   \n",
       "29                                CVS/Pharmacy #11170   \n",
       "30                     Hope Partnership for Education   \n",
       "31                                           Gong Cha   \n",
       "32                                          Girard BP   \n",
       "33                                  Girard Annex GAMP   \n",
       "34                 Famous Gourmet Deli and Restaurant   \n",
       "35                           Advance Auto Parts #8775   \n",
       "36                                 Asad's Hot Chicken   \n",
       "37                             Eliza Kirkbride School   \n",
       "38                        High Time Convenience Store   \n",
       "39                                Hare Krishna Temple   \n",
       "40                                   Haegele's Bakery   \n",
       "41                                              FedEx   \n",
       "42                                        CVS - #2986   \n",
       "43                                    Cuddle 'n' Care   \n",
       "44                                        China House   \n",
       "45                                  Chill on the Hill   \n",
       "46                                  Cathedral Village   \n",
       "47                               Bayard Taylor School   \n",
       "48                   Ali, Mansoor /Bilal Gyro/ V07637   \n",
       "49                                    Benny Peretti's   \n",
       "\n",
       "                             address  foodborne_count  \\\n",
       "0           4603 FRANKFORD AVE 19124                5   \n",
       "1               1500 LOCUST ST 19102                5   \n",
       "2              716 RED LION RD 19115                5   \n",
       "3             1730 CHESTNUT ST 19103                5   \n",
       "4                814 S 47TH ST 19143                4   \n",
       "5        7300 E ROOSEVELT BLVD 19149                4   \n",
       "6               2848 S 17TH ST 19145                4   \n",
       "7          2655 S ISEMINGER ST 19148                3   \n",
       "8              2000 MEDARY AVE 19138                2   \n",
       "9            435 FAIRMOUNT AVE 19123                2   \n",
       "10             5801 OXFORD AVE 19149                2   \n",
       "11                23 S 38TH ST 19104                2   \n",
       "12              9037 ASHTON RD 19136                2   \n",
       "13      NON PERMANENT LOCATION 19107                1   \n",
       "14          6001 LANCASTER AVE 19151                1   \n",
       "15           2750 ARAMINGO AVE 19134                1   \n",
       "16              602 W ERIE AVE 19140                1   \n",
       "17               2965 N 3RD ST 19133                1   \n",
       "18          4613 FRANKFORD AVE 19124                1   \n",
       "19             3343 N BROAD ST 19140                1   \n",
       "20         1500 E PASSYUNK AVE 19147                1   \n",
       "21         5824 RISING SUN AVE 19120                1   \n",
       "22        1532 E WADSWORTH AVE 19150                1   \n",
       "23             1835 SNYDER AVE 19145                1   \n",
       "24          1811 FAIRMOUNT AVE 19130                1   \n",
       "25               3323 TUDOR ST 19136                1   \n",
       "26               4163 N 9TH ST 19140                1   \n",
       "27                 6 S 13TH ST 19107                1   \n",
       "28               262 S 19TH ST 19103                1   \n",
       "29              1201 WALNUT ST 19107                1   \n",
       "30              2601 N 11TH ST 19133                1   \n",
       "31  1122 WASHINGTON AVE UNIT J 19147                1   \n",
       "32           4708 W GIRARD AVE 19131                1   \n",
       "33              2198 RITNER ST 19145                1   \n",
       "34              1619 GRANT AVE 19115                1   \n",
       "35    8423 FRANKFORD AVE STE A 19136                0   \n",
       "36              1247 S 47TH ST 19143                0   \n",
       "37              1501 S 07TH ST 19147                0   \n",
       "38     1702 CECIL B. MOORE AVE 19121                0   \n",
       "39              41 W ALLENS LN 19119                0   \n",
       "40             4164 BARNETT ST 19135                0   \n",
       "41               216 S 16TH ST 19102                0   \n",
       "42             7065 LINCOLN DR 19119                0   \n",
       "43         7707 GERMANTOWN AVE 19118                0   \n",
       "44        331 SPRING GARDEN ST 19123                0   \n",
       "45      5 E HIGHLAND AVE SPC 1 19118                0   \n",
       "46          600 E CATHEDRAL RD 19128                0   \n",
       "47              528 W ERIE AVE 19140                0   \n",
       "48            2420 COTTMAN AVE 19149                0   \n",
       "49                4320 MAIN ST 19127                0   \n",
       "\n",
       "                                                  url  \n",
       "0   https://data.inquirer.com/inspections/philly/?...  \n",
       "1   https://data.inquirer.com/inspections/philly/?...  \n",
       "2   https://data.inquirer.com/inspections/philly/?...  \n",
       "3   https://data.inquirer.com/inspections/philly/?...  \n",
       "4   https://data.inquirer.com/inspections/philly/?...  \n",
       "5   https://data.inquirer.com/inspections/philly/?...  \n",
       "6   https://data.inquirer.com/inspections/philly/?...  \n",
       "7   https://data.inquirer.com/inspections/philly/?...  \n",
       "8   https://data.inquirer.com/inspections/philly/?...  \n",
       "9   https://data.inquirer.com/inspections/philly/?...  \n",
       "10  https://data.inquirer.com/inspections/philly/?...  \n",
       "11  https://data.inquirer.com/inspections/philly/?...  \n",
       "12  https://data.inquirer.com/inspections/philly/?...  \n",
       "13  https://data.inquirer.com/inspections/philly/?...  \n",
       "14  https://data.inquirer.com/inspections/philly/?...  \n",
       "15  https://data.inquirer.com/inspections/philly/?...  \n",
       "16  https://data.inquirer.com/inspections/philly/?...  \n",
       "17  https://data.inquirer.com/inspections/philly/?...  \n",
       "18  https://data.inquirer.com/inspections/philly/?...  \n",
       "19  https://data.inquirer.com/inspections/philly/?...  \n",
       "20  https://data.inquirer.com/inspections/philly/?...  \n",
       "21  https://data.inquirer.com/inspections/philly/?...  \n",
       "22  https://data.inquirer.com/inspections/philly/?...  \n",
       "23  https://data.inquirer.com/inspections/philly/?...  \n",
       "24  https://data.inquirer.com/inspections/philly/?...  \n",
       "25  https://data.inquirer.com/inspections/philly/?...  \n",
       "26  https://data.inquirer.com/inspections/philly/?...  \n",
       "27  https://data.inquirer.com/inspections/philly/?...  \n",
       "28  https://data.inquirer.com/inspections/philly/?...  \n",
       "29  https://data.inquirer.com/inspections/philly/?...  \n",
       "30  https://data.inquirer.com/inspections/philly/?...  \n",
       "31  https://data.inquirer.com/inspections/philly/?...  \n",
       "32  https://data.inquirer.com/inspections/philly/?...  \n",
       "33  https://data.inquirer.com/inspections/philly/?...  \n",
       "34  https://data.inquirer.com/inspections/philly/?...  \n",
       "35  https://data.inquirer.com/inspections/philly/?...  \n",
       "36  https://data.inquirer.com/inspections/philly/?...  \n",
       "37  https://data.inquirer.com/inspections/philly/?...  \n",
       "38  https://data.inquirer.com/inspections/philly/?...  \n",
       "39  https://data.inquirer.com/inspections/philly/?...  \n",
       "40  https://data.inquirer.com/inspections/philly/?...  \n",
       "41  https://data.inquirer.com/inspections/philly/?...  \n",
       "42  https://data.inquirer.com/inspections/philly/?...  \n",
       "43  https://data.inquirer.com/inspections/philly/?...  \n",
       "44  https://data.inquirer.com/inspections/philly/?...  \n",
       "45  https://data.inquirer.com/inspections/philly/?...  \n",
       "46  https://data.inquirer.com/inspections/philly/?...  \n",
       "47  https://data.inquirer.com/inspections/philly/?...  \n",
       "48  https://data.inquirer.com/inspections/philly/?...  \n",
       "49  https://data.inquirer.com/inspections/philly/?...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_df.sort_values(\"foodborne_count\", ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See any restaurants you recognize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Web scraping exercise\n",
    "\n",
    "Use the Web Inspector to inspect the structure of the relevant web page, and identify the HTML content you will need to scrape with Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### How many millions of people are currently experiencing drought?\n",
    "\n",
    "Relevant URL: [https://www.drought.gov/current-conditions](https://www.drought.gov/current-conditions)\n",
    "\n",
    "**Hint:** We're interested in just a single HTML element so you can inspect the website, identify the right element, and copy the selector for the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the request\n",
    "url = \"https://www.drought.gov/current-conditions\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Initialize the soup for this page\n",
    "soup2 = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selector = \"#block-uswds-drought-content > div > div > div.grid-container.grid-container--standard.padding-top-6 > div:nth-child(5) > div > div:nth-child(3) > div > div > div.u--color--accent.text-center.font-sans-xl.field.field--name-field-number-stat.field--type-string.field--label-hidden\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'150.3 Million'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select_one(selector).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the Weitzman School directory\n",
    "\n",
    "The Weitzman School lists their directory of people on this page: [https://www.design.upenn.edu/people/list](https://www.design.upenn.edu/people/list). From this site, let's extract out following information:\n",
    "\n",
    "- The person's name;\n",
    "- title, and;\n",
    "- associated department.\n",
    "\n",
    "The info we want for each person is wrapped up in a `<div>` element. You can select all of those elements, loop over each one in a \"for\" loop, extract the three pieces of content we want from each `<div>`, and then save the result to a list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the request\n",
    "url = \"https://www.design.upenn.edu/people/list\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Initialize the soup for this page\n",
    "soup3 = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select all rows\n",
    "rows = soup3.select(\".views-row\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"views-row\">\n",
      " <a class=\"list-item profile-item\" href=\"/people/zhan-shi\">\n",
      "  <span class=\"text\">\n",
      "   <span class=\"title heading-5\">\n",
      "    Zhan Shi\n",
      "   </span>\n",
      "   <span class=\"meta body-small\">\n",
      "    Ph.D. student\n",
      "   </span>\n",
      "  </span>\n",
      "  <span class=\"dept body-subhead\">\n",
      "   Thermal Architecture Lab\n",
      "  </span>\n",
      "  <span class=\"arrow\">\n",
      "   <span aria-hidden=\"true\" class=\"fa fa-arrow-right\">\n",
      "   </span>\n",
      "  </span>\n",
      " </a>\n",
      " <div class=\"views-field views-field-edit-node-1 edit\">\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract out specific content from each row\n",
    "print(rows[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>title</th>\n",
       "      <th>dept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zhan Shi</td>\n",
       "      <td>Ph.D. student</td>\n",
       "      <td>Thermal Architecture Lab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Abel</td>\n",
       "      <td>External Faculty Collaborator</td>\n",
       "      <td>Center for Environmental Building &amp; Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Mostafa Akbari</td>\n",
       "      <td>PhD Architecture Alum, 2024</td>\n",
       "      <td>Architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masoud  Akbarzadeh</td>\n",
       "      <td>Assistant Professor of Architecture</td>\n",
       "      <td>Architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scott Aker</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>Architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Cynthia Zhou</td>\n",
       "      <td>Animator Researcher//Design and Fine Arts</td>\n",
       "      <td>Penn Animation as Research Lab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>Emily Zimmerman</td>\n",
       "      <td>Guest Curator and Visiting Critic 2024-2025</td>\n",
       "      <td>Fine Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Jessica Zofchak</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>Architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Syd Zolf</td>\n",
       "      <td>Artist in Residence CPCW &amp; GSWS, FNAR Lecturer</td>\n",
       "      <td>Fine Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Selina Chuan-Zou</td>\n",
       "      <td>MSHP</td>\n",
       "      <td>Admissions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 person                                           title  \\\n",
       "0              Zhan Shi                                   Ph.D. student   \n",
       "1              Tom Abel                   External Faculty Collaborator   \n",
       "2    Dr. Mostafa Akbari                     PhD Architecture Alum, 2024   \n",
       "3    Masoud  Akbarzadeh             Assistant Professor of Architecture   \n",
       "4            Scott Aker                                        Lecturer   \n",
       "..                  ...                                             ...   \n",
       "573        Cynthia Zhou       Animator Researcher//Design and Fine Arts   \n",
       "574     Emily Zimmerman     Guest Curator and Visiting Critic 2024-2025   \n",
       "575     Jessica Zofchak                                        Lecturer   \n",
       "576            Syd Zolf  Artist in Residence CPCW & GSWS, FNAR Lecturer   \n",
       "577    Selina Chuan-Zou                                            MSHP   \n",
       "\n",
       "                                           dept  \n",
       "0                      Thermal Architecture Lab  \n",
       "1    Center for Environmental Building & Design  \n",
       "2                                  Architecture  \n",
       "3                                  Architecture  \n",
       "4                                  Architecture  \n",
       "..                                          ...  \n",
       "573              Penn Animation as Research Lab  \n",
       "574                                   Fine Arts  \n",
       "575                                Architecture  \n",
       "576                                   Fine Arts  \n",
       "577                                  Admissions  \n",
       "\n",
       "[578 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save content here\n",
    "data = []\n",
    "\n",
    "# Loop over all rows\n",
    "for row in rows:\n",
    "    # Person name\n",
    "    person = row.select_one(\".title\").text\n",
    "\n",
    "    # Title\n",
    "    title = row.select_one(\".meta\").text\n",
    "\n",
    "    # Deptarment\n",
    "    dept = row.select_one(\".dept\").text.strip()\n",
    "\n",
    "    data.append({\"person\": person, \"title\": title, \"dept\": dept})\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
